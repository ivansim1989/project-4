{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import numpy as np\n",
    "import urllib\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job searching - My career futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = [\"https://www.mycareersfuture.sg/search?search=data%20scientist&page={}\", # data scientist \n",
    "       \"https://www.mycareersfuture.sg/search?search=business%20intelligence&page={}\", # business intelligence\n",
    "       \"https://www.mycareersfuture.sg/search?search=data%20analyst&page={}\", # data analyst\n",
    "       \"https://www.mycareersfuture.sg/search?search=machine%20learning&page={}\", # machine learning,\n",
    "       \"https://www.mycareersfuture.sg/search?search=business%20analyst&page={}\", # business analyst page\n",
    "       \"https://www.mycareersfuture.sg/search?search=data%20engineer&page={}\", #data engineer\n",
    "       \"https://www.mycareersfuture.sg/search?search=artificial%20intelligence&page={}\",# artificial intelligence\n",
    "       \"https://www.mycareersfuture.sg/search?search=Data%20Architect&page={}\", # Data Architect\n",
    "       \"https://www.mycareersfuture.sg/search?search=Research%20Scientist&page={}\", # Resarch Scientist Architect\n",
    "       \"https://www.mycareersfuture.sg/search?search=Finance%20Analyst&page={}\" # Finance Analyst\n",
    "      ]\n",
    "\n",
    "job_urls = []\n",
    "\n",
    "# iterate the url and selenium the html\n",
    "for links in url:\n",
    "    # iterate 0 to 20 pages \n",
    "    for pages in range(0,20+1): \n",
    "        #Controls the ChromeDriver and allows you to drive the browser.\n",
    "        driver = webdriver.Chrome(executable_path=\"/Users/ivans/Desktop/GA/chromedriver.exe\")\n",
    "    \n",
    "        #Loads a web page in the current browser session\n",
    "        driver.get(links.format(pages))\n",
    "    \n",
    "        # Delay execution for a given number of seconds.\n",
    "        sleep(4)\n",
    "    \n",
    "        # Defines the basic interface called by the tree builders.\n",
    "        html = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        # iterate through job cards and get relevant details (https://stackoverflow.com/questions/2830530/matching-ids-in-beautifulsoup)\n",
    "        for job_card in html.find_all('div', id=lambda x: x and x.startswith('job-card-')):\n",
    "            job_urls.append('https://www.mycareersfuture.sg'+job_card.find('a')['href'])\n",
    "      \n",
    "        # close the webspage after ger ther relavant details  \n",
    "        driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1242"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the list to set due to the set removes all duplicate elements\n",
    "job_urls2 = set(job_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the sets to the list again then convert it to dataframe then csv\n",
    "job_df=pd.DataFrame(list(job_urls2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csv\n",
    "# job_df_DS = pd.read_csv('job_url2_DS.csv')\n",
    "# get the value of the job site columns\n",
    "job_ls = job_df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create lists for information needed\n",
    "companies = []\n",
    "titles = []\n",
    "addresses = []\n",
    "emp_type = []\n",
    "seniority = []\n",
    "category = []\n",
    "salaries = []\n",
    "responsibilities = []\n",
    "requirements = []\n",
    "failed_url = []\n",
    "\n",
    "# Controls the ChromeDriver and allows you to drive the browser.\n",
    "driver = webdriver.Chrome(executable_path=\"/Users/ivans/Desktop/GA/chromedriver.exe\")\n",
    "\n",
    "# In order to iterate every columns by its index, we return an enumerate object.\n",
    "for index, url_job in enumerate(job_ls[0:1070]):\n",
    "     \n",
    "    try:\n",
    "        # iterate the web page from the list (job_ls)\n",
    "        #Loads a web page in the current browser session\n",
    "        driver.get(url_job)\n",
    "        # Delay execution for a given number of seconds.\n",
    "        sleep(4)\n",
    "        html_job = driver.page_source\n",
    "        # Defines the basic interface called by the tree builders\n",
    "        soup_job = BeautifulSoup(html_job, \"lxml\")\n",
    "        # Append the related information to \n",
    "        companies.append(soup_job.find('p', {'id': 'company'}))\n",
    "        titles.append(soup_job.find('h1', {'id': 'job_title'}))\n",
    "        addresses.append(soup_job.find('p', {'id': 'address'}))    \n",
    "        emp_type.append(soup_job.find('p', {'id': 'employment_type'}))\n",
    "        seniority.append(soup_job.find('p', {'id': 'seniority'}))\n",
    "        category.append(soup_job.find('p', {'id': 'job-categories'}))\n",
    "        salaries.append(soup_job.find('div', {'class': 'lh-solid'}))\n",
    "        responsibilities.append(soup_job.find('div',{'id':'job_description'}))\n",
    "        requirements.append(soup_job.find('div',{'id':'requirements'}))\n",
    "    except:\n",
    "        failed_url.append(url_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequence and structure of the dataframe\n",
    "lists = [companies, titles, addresses, emp_type, seniority, category, salaries, responsibilities, requirements]\n",
    "# Create a dictionary\n",
    "clean = {}\n",
    "\n",
    "# In order to iterate every columns by its index, we return an enumerate object.\n",
    "for index, items in enumerate(lists):\n",
    "    # Create a list for the dictionary, keys = index, values = items we gonna to append\n",
    "    clean[index] = []\n",
    "    # We use the try and except to append the text of the elements (excluding the html code). If not, the list index will be out of range \n",
    "    for elements in items:\n",
    "        try:\n",
    "            clean[index].append(elements.text)\n",
    "        except:\n",
    "            clean[index].append(None)\n",
    "            \n",
    "# Convert dictionary into dataframe\n",
    "df_job_mycareersfuture = pd.DataFrame(clean) \n",
    "# Rename columns\n",
    "df_job_mycareersfuture.columns = ['titles', 'companies', 'locations', 'category', 'emp_type', 'seniority', 'salaries', 'responsibilities', 'requirements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1012, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_job_mycareersfuture.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_job_mycareersfuture.to_csv('df_job_mycareersfuture.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
